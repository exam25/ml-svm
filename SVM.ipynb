{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f9ff873-3fa0-48e5-8328-2a2d2380ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bac28e0-02c7-44ac-be75-e43562f28c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart_disease.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26a944f9-8730-4a54-a110-08e67814ee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69       123\n",
      "           1       0.71      0.77      0.74       134\n",
      "\n",
      "    accuracy                           0.72       257\n",
      "   macro avg       0.72      0.71      0.71       257\n",
      "weighted avg       0.72      0.72      0.71       257\n",
      "\n",
      "[[ 81  42]\n",
      " [ 31 103]]\n",
      "\n",
      "Precision : 0.7103448275862069\n",
      "Recall : 0.7686567164179104\n",
      "Specificity: 0.6585365853658537\n",
      "\n",
      "rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65       123\n",
      "           1       0.68      0.81      0.74       134\n",
      "\n",
      "    accuracy                           0.70       257\n",
      "   macro avg       0.71      0.70      0.69       257\n",
      "weighted avg       0.71      0.70      0.70       257\n",
      "\n",
      "[[ 72  51]\n",
      " [ 26 108]]\n",
      "\n",
      "Precision : 0.6792452830188679\n",
      "Recall : 0.8059701492537313\n",
      "Specificity: 0.5853658536585366\n",
      "\n",
      "sigmoid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62       123\n",
      "           1       0.65      0.70      0.68       134\n",
      "\n",
      "    accuracy                           0.65       257\n",
      "   macro avg       0.65      0.65      0.65       257\n",
      "weighted avg       0.65      0.65      0.65       257\n",
      "\n",
      "[[73 50]\n",
      " [40 94]]\n",
      "\n",
      "Precision : 0.6527777777777778\n",
      "Recall : 0.7014925373134329\n",
      "Specificity: 0.5934959349593496\n"
     ]
    }
   ],
   "source": [
    "x = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "xtr, xte, ytr, yte = train_test_split(x, y)\n",
    "\n",
    "kernels = ['poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "    model = svm.SVC(kernel=kernel)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    print()\n",
    "    print(kernel)\n",
    "    print(metrics.classification_report(yte, model.predict(xte)))\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(yte, model.predict(xte)).ravel()\n",
    "    \n",
    "    print(metrics.confusion_matrix(yte, model.predict(xte)))\n",
    "    print(f\"\\nPrecision : {tp/(tp+fp)}\")\n",
    "    print(f\"Recall : {tp/(tp+fn)}\")\n",
    "    print(f\"Specificity: {tn/(tn+fp)}\")\n",
    "    #Fscore = 2 * (Precision * Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49435bc-b5df-4d3d-8bd0-6704d2e8fcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix in module sklearn.metrics._classification:\n",
      "\n",
      "confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
      "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
      "    \n",
      "    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "    is equal to the number of observations known to be in group :math:`i` and\n",
      "    predicted to be in group :math:`j`.\n",
      "    \n",
      "    Thus in binary classification, the count of true negatives is\n",
      "    :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "    :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array-like of shape (n_samples,)\n",
      "        Ground truth (correct) target values.\n",
      "    \n",
      "    y_pred : array-like of shape (n_samples,)\n",
      "        Estimated targets as returned by a classifier.\n",
      "    \n",
      "    labels : array-like of shape (n_classes), default=None\n",
      "        List of labels to index the matrix. This may be used to reorder\n",
      "        or select a subset of labels.\n",
      "        If ``None`` is given, those that appear at least once\n",
      "        in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        Sample weights.\n",
      "    \n",
      "        .. versionadded:: 0.18\n",
      "    \n",
      "    normalize : {'true', 'pred', 'all'}, default=None\n",
      "        Normalizes confusion matrix over the true (rows), predicted (columns)\n",
      "        conditions or all the population. If None, confusion matrix will not be\n",
      "        normalized.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    C : ndarray of shape (n_classes, n_classes)\n",
      "        Confusion matrix whose i-th row and j-th\n",
      "        column entry indicates the number of\n",
      "        samples with true label being i-th class\n",
      "        and predicted label being j-th class.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
      "        given an estimator, the data, and the label.\n",
      "    ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
      "        given the true and predicted labels.\n",
      "    ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Confusion matrix\n",
      "           <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "           (Wikipedia and other references may use a different\n",
      "           convention for axes).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.metrics import confusion_matrix\n",
      "    >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "    >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "    >>> confusion_matrix(y_true, y_pred)\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "    >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "    >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "    array([[2, 0, 0],\n",
      "           [0, 0, 1],\n",
      "           [1, 0, 2]])\n",
      "    \n",
      "    In the binary case, we can extract true positives, etc. as follows:\n",
      "    \n",
      "    >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "    >>> (tn, fp, fn, tp)\n",
      "    (0, 2, 1, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(metrics.confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
